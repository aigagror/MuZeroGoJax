# Game settings
--board_size=7
--trajectory_length=99
--batch_size=64
--self_play_model=
--self_play_sample_action_size=2

# Train settings
--lr_warmup_steps=100
--max_hypothetical_steps=4
--model_updates_per_train_step=4
--optimizer=adamw
--training_steps=30000
--learning_rate=0.0001


# Model settings
--dtype=float32
--broadcast_frequency=8
--bottleneck_div=4
--hdim=256

--area_model=ResNetV2Decode
--decode_nlayers=1

--embed_dim=256
--embed_model=CanonicalResNetV2Embed
--embed_nlayers=16

--policy_model=ResNetV2Policy
--policy_nlayers=1

--transition_model=ResNetV2Transition
--transition_nlayers=8

--value_model=ResNetV2Value
--value_nlayers=1

# Loss settings
--noadd_area_loss
--add_hypo_area_loss
--add_hypo_value_loss
--add_policy_loss
--add_value_loss
--loss_sample_action_size=2
--qval_scale=50.0

# Metric settings
--log_training_frequency=50
--eval_elo_frequency=2000
--noplay_as_white
--save_dir=/tmp/checkpoint/
--noskip_elo_eval
--noskip_plot
--nolog_loss_values
--skip_play
